{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b43d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.models as models\n",
    "from torch.nn import Module, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "import torchvision\n",
    "\n",
    "#from pytorchtools import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import logging\n",
    "\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.model_selection import KFold\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0958986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eudari01/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                    transforms.Resize(224),\n",
    "                                    transforms.RandomVerticalFlip(),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ColorJitter(brightness=0, contrast=0, saturation=1, hue=.5),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "val_transforms= transforms.Compose([\n",
    "                                    transforms.Resize(224),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "\n",
    "# cross validaion with 5 folders on the train \n",
    "train_dataset = datasets.ImageFolder('/path/to/your/tiles', train_transforms) \n",
    "\n",
    "# cross validaion with 5 folders on the val \n",
    "val_dataset = datasets.ImageFolder('/path/to/your/tiles', val_transforms) \n",
    "\n",
    "\n",
    "batch_size = 48\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "valid_loader= torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad86a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe805635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_19_Regression(Module):\n",
    "    \n",
    "    def __init__(self,dropout=0.8):\n",
    "        \n",
    "        \n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn',weights = None)\n",
    "        \n",
    "        super(VGG_19_Regression,self).__init__()\n",
    "        self.model= model\n",
    "        self.Regression = nn.Linear(1000,1)\n",
    "        self.Batch=nn.BatchNorm1d(1000)\n",
    "        #self.Flatten=nn.Flatten()\n",
    "        self.dropout = Dropout(float(dropout))\n",
    "        \n",
    "           \n",
    "         \n",
    "    def forward(self, out):\n",
    "        \n",
    "      \n",
    "        x= self.model(out)\n",
    "        \n",
    "        x=self.Batch(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x =self.Regression(x) \n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bfd92fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/eudari01/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "Model= VGG_19_Regression()\n",
    "MSE = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(Model.parameters(), lr=0.001,momentum=0.9, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba5aacea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f80541a4590>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    Model = nn.DataParallel(Model)\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "#Model.to(device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c8ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy=[]\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "r2_score_train=[]\n",
    "r2_score_val= []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def training(epochs):\n",
    "\n",
    "      \n",
    "        \n",
    "                \n",
    "                    \n",
    "        Model.train()              \n",
    "        epoch_loss = 0.0\n",
    "        running_loss_train=0.0\n",
    "   \n",
    "        for inputs, label in tqdm(train_loader):\n",
    "        \n",
    "                  inputs= inputs.to(device)\n",
    "                  label = label.to(device)\n",
    "                \n",
    "                \n",
    "                  label= label.to(torch.float32)\n",
    "    \n",
    "                  label = label.unsqueeze(1)\n",
    "                  optimizer.zero_grad()\n",
    "                  \n",
    "                  output = Model(inputs)\n",
    "       \n",
    "                  loss = MSE(output,label)\n",
    "\n",
    "            \n",
    "                  loss.backward()\n",
    "                  optimizer.step()\n",
    "                \n",
    "            #Calculate prediction\n",
    "                  prediction_train=output.argmax(dim=1)\n",
    "\n",
    "                \n",
    "        \n",
    "                  running_loss_train =+ loss.item()* inputs.size(0) \n",
    "            #Epoch\n",
    "            \n",
    "                  epoch_loss += running_loss_train / len(train_loader)\n",
    "                  r2_score_train=r2_score(label,prediction_train)\n",
    "                \n",
    "  \n",
    "        \n",
    "        # save the model after training \n",
    "        torch.save(Model(), \"\")\n",
    "            \n",
    "        Model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        running_loss_val= 0.0\n",
    "       \n",
    "        \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            for inputs, label in valid_loader:\n",
    "                \n",
    "                        \n",
    "                        inputs= inputs.to(device)\n",
    "                        label = label.to(device)\n",
    "                        \n",
    "                        label= label.to(torch.float32)\n",
    "                        label = label.unsqueeze(1)\n",
    "\n",
    "                        output = Model(inputs)\n",
    "                \n",
    "                        loss = MSE(output, label)\n",
    "                \n",
    "              \n",
    "                        prediction_val= output.argmax(dim=1)\n",
    "                    \n",
    "                \n",
    "                #mse_val=mean_squared_error(label,prediction_val)\n",
    "                \n",
    "                #val_acc = (prediction_val == label).float().mean()\n",
    "                \n",
    "                        running_loss_val =+ loss.item()* inputs.size(0) \n",
    "               \n",
    "                #Epoch  \n",
    "                    \n",
    "                        epoch_val_loss += running_loss_val / len(valid_loader)\n",
    "                        r2_score_val= r2_score( label,prediction_val)\n",
    "                        \n",
    "        #to resset the train and validation for each split           \n",
    "   \n",
    "     \n",
    "                    \n",
    "                        \n",
    "        val_loss.append(epoch_val_loss)\n",
    "        train_loss.append(epoch_loss)\n",
    "        \n",
    "  \n",
    "\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - train_loss : {epoch_loss:.4f} - val_loss : {epoch_val_loss:.4f} -r2_score_train:{r2_score_train:.4f}-r2_score_val:{r2_score_val:.4f}\\n\")\n",
    "        \n",
    "                \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        return epoch_loss, epoch_val_loss,r2_score_train,r2_score_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9440fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 13/13 [02:19<00:00, 10.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 - train_loss : 30.8897 - val_loss : 16.4911 -Split: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=15\n",
    "for epoch in range(1,epochs+1):\n",
    "     results_df=training(epoch)\n",
    "     \n",
    "     results_df.to_csv('/data/results_optuna.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ef28e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5785d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective (trial):\n",
    "    \n",
    "    \n",
    "    param={   \n",
    "    'batch_size': trial.suggest_int('batch_size',10,60),\n",
    "    'lr': trial.suggest_loguniform('lr',1e-7, 1e-1),\n",
    "    'dropout': trial.suggest_loguniform('dropout',0.3,0.9),\n",
    "    'momentum' : trial.suggest_loguniform('momentum',0.1,0.9),\n",
    "     'weight_decay': trial.suggest_loguniform('weight_decay',1e-5, 1e-1)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    val_transforms= transforms.Compose([\n",
    "                                    transforms.Resize(224),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "    val_dataset = datasets.ImageFolder('/path/data/validation', val_transforms) \n",
    "\n",
    "    valid_loader= torch.utils.data.DataLoader(val_dataset, param[\"batch_size\"], num_workers=16, shuffle=True)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(Model.parameters(), param[\"lr\"],param[\"momentum\"],param[\"weight_decay\"])\n",
    "    \n",
    "    \n",
    "    #Model=Model(param[\"dropout\"])  \n",
    "    Model.eval()\n",
    "    MSE = torch.nn.MSELoss()\n",
    " \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "        #cross validation \n",
    "  \n",
    "                \n",
    "        \n",
    "    epoch_val_loss = 0.0\n",
    "    running_loss_val= 0.0\n",
    "          \n",
    "        \n",
    "    for data, label in valid_loader:\n",
    "        \n",
    "            label= label.to(torch.float32)\n",
    "                  \n",
    "            label = torch.unsqueeze(label,1)\n",
    "                        \n",
    "            output = Model(data)\n",
    "                \n",
    "            loss = MSE(output, label)\n",
    "                \n",
    "            prediction_val= output.argmax(dim=1)\n",
    "                \n",
    "             \n",
    "                \n",
    "            running_loss_val =+ loss.item()* data.size(0) \n",
    "                   \n",
    "               \n",
    "                #Epoch\n",
    "               \n",
    "            epoch_val_loss += running_loss_val / len(valid_loader)\n",
    "                        \n",
    "            val_loss=[]\n",
    "            val_loss.append(epoch_val_loss)\n",
    "                \n",
    "                        \n",
    "    return epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "747a35a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-29 11:13:10,464]\u001b[0m A new study created in memory with name: no-name-087c3127-95e9-4a01-bc5f-94bd1bf30eea\u001b[0m\n",
      "\u001b[33m[W 2022-08-29 11:13:10,469]\u001b[0m Trial 0 failed because of the following error: FileNotFoundError(2, 'No such file or directory')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/eudari01/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_61127/1359690696.py\", line 17, in objective\n",
      "    val_dataset = datasets.ImageFolder('/data/tiles_CIN/val/', val_transforms)\n",
      "  File \"/Users/eudari01/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 310, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/eudari01/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 145, in __init__\n",
      "    classes, class_to_idx = self.find_classes(self.root)\n",
      "  File \"/Users/eudari01/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 219, in find_classes\n",
      "    return find_classes(directory)\n",
      "  File \"/Users/eudari01/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 41, in find_classes\n",
      "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/tiles_CIN/val/'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/tiles_CIN/val/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61127/3644804477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_61127/1359690696.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                     transforms.ToTensor()])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/tiles_CIN/val/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     ):\n\u001b[0;32m--> 310\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m     ) -> None:\n\u001b[1;32m    144\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/tiles_CIN/val/'"
     ]
    }
   ],
   "source": [
    "    sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "    study = optuna.create_study(direction='minimize',sampler=sampler)\n",
    "\n",
    "    study.optimize(objective, n_trials=1)\n",
    "\n",
    "    trial = study.best_trial\n",
    "\n",
    "\n",
    "    print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "    \n",
    "    #print(\"Best hyperparameters2: {}\".format(study.best_params))\n",
    "    print(\"\\nBest MSE : {}\".format(study.best_value) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a750c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "340b3396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
