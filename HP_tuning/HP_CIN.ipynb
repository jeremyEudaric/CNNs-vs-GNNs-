{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988571df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    " #-*- coding: utf-8 -*-\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.models as models\n",
    "from torch.nn import Module, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "import torchvision\n",
    "\n",
    "#from pytorchtools import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6055a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_19_Regression(Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        \n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\n",
    "        \n",
    "        super(VGG_19_Regression,self).__init__()\n",
    "        self.model= model\n",
    "        self.Regression = nn.Linear(1000,1)\n",
    "        self.dropout = Dropout(dropout=0.5)\n",
    "        \n",
    "           \n",
    "         \n",
    "    def forward(self, out):\n",
    "        \n",
    "        x= self.model(out)\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x =self.Regression(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7584cc96",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/scratchc/fmlab/eudari01/BREAST_METABRIC/tiles_CIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10004/1471367546.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# cross validaion with 5 folders on the train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/scratchc/fmlab/eudari01/BREAST_METABRIC/tiles_CIN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# cross validaion with 5 folders on the val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     ):\n\u001b[0;32m--> 310\u001b[0;31m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[1;32m    311\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m    144\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/scratchc/fmlab/eudari01/BREAST_METABRIC/tiles_CIN'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def training(epoch):\n",
    "     \n",
    "        \n",
    "    train_transforms = transforms.Compose([\n",
    "                                    transforms.Resize(224),\n",
    "                                    transforms.RandomVerticalFlip(),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ColorJitter(brightness=0, contrast=0, saturation=1, hue=.5),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "    val_transforms= transforms.Compose([\n",
    "                                    transforms.Resize(224),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "\n",
    "    # cross validaion with 5 folders on the train \n",
    "    train_dataset = datasets.ImageFolder('/mnt/scratchc/fmlab/eudari01/BREAST_METABRIC/tiles_CIN', train_transforms) \n",
    "\n",
    "    # cross validaion with 5 folders on the val \n",
    "    val_dataset = datasets.ImageFolder('/mnt/scratchc/fmlab/eudari01/BREAST_METABRIC/tiles_CIN', val_transforms) \n",
    "\n",
    "\n",
    "    batch_size = 48\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "    valid_loader= torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "\n",
    "    Model= VGG_19_Regression()\n",
    "    MSE = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(Model.parameters(), lr=0.00001,momentum=0.9)  \n",
    "    \n",
    "    for i in range(5) : \n",
    "        \n",
    "        \n",
    "        for layer in Model.children():\n",
    "                   if hasattr(layer, 'reset_parameters'):\n",
    "                    layer.reset_parameters()\n",
    "        Model.train()              \n",
    "        epoch_loss = 0.0\n",
    "        running_loss_train=0.0\n",
    "   \n",
    "        for data, label in tqdm(train_loader):\n",
    "        \n",
    "                  label= label.to(torch.float32)\n",
    "                  label = label.unsqueeze(1)\n",
    "\n",
    "         \n",
    "        #Transfer Data to GPU if available\n",
    "            #if torch.cuda.is_available():\n",
    "            \n",
    "            \n",
    "                #data = data.cuda()\n",
    "                #label = label.cuda()\n",
    "            \n",
    "                  output = Model(data)\n",
    "            #you can change the loss and use MSE or Cross Entropy\n",
    "                  loss = MSE(output,label)\n",
    "           \n",
    "            # Clear the gradients\n",
    "                  optimizer.zero_grad()\n",
    "            \n",
    "                  loss.backward()\n",
    "                  optimizer.step()\n",
    "                \n",
    "            #Calculate accuracy \n",
    "            #prediction_train=output.argmax(dim=1)\n",
    "           # acc = (prediction_train== label1).float().mean()\n",
    "        \n",
    "                  running_loss_train =+ loss.item()* data.size(0) \n",
    "            #Epoch\n",
    "            #epoch_accuracy += acc.item() / len(train_loader)\n",
    "                  epoch_loss += running_loss_train / len(train_loader)\n",
    "                  r2_score_train=r2_score(label, prediction_train)\n",
    "            \n",
    "            \n",
    "        Model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        running_loss_val= 0.0\n",
    "        min_val_loss=0.0\n",
    "        epochs_no_improve =0\n",
    "        n_epochs_stop = 20\n",
    "        \n",
    "        for layer in Model.children():\n",
    "                   if hasattr(layer, 'reset_parameters'):\n",
    "                    layer.reset_parameters()\n",
    "        \n",
    "        \n",
    "        for data, label in valid_loader:\n",
    "            \n",
    "                        output = Model(data)\n",
    "                \n",
    "                        loss = MSE(output, label)\n",
    "                \n",
    "                # Clear the gradients\n",
    "                #optimizer.zero_grad()\n",
    "                \n",
    "                #val_loss.backward()\n",
    "                \n",
    "                #optimizer.step()\n",
    "                #Calculate accuracy \n",
    "                #prediction_val= val_output.argmax(dim=1)\n",
    "                \n",
    "                #mse_val=mean_squared_error(label,prediction_val)\n",
    "                \n",
    "                #val_acc = (prediction_val == label).float().mean()\n",
    "                \n",
    "                        running_loss_val =+ loss.item()* data.size(0) \n",
    "               \n",
    "                #Epoch\n",
    "                #epoch_val_accuracy += val_acc.item() / len(valid_loader)\n",
    "                        epoch_val_loss += running_loss_val / len(valid_loader)\n",
    "                        r2_score_val= r2_score(label, prediction_val)\n",
    "        \n",
    "        #to resset the train and validation for each split\n",
    "        for layer in Model.children():\n",
    "                   if hasattr(layer, 'reset_parameters'):\n",
    "                    layer.reset_parameters()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if  running_loss_val < min_val_loss:\n",
    "                      # Save the model\n",
    "                torch.save(Model)\n",
    "                #epochs_no_improve = 0\n",
    "                #n_epochs_stop = 20\n",
    "                min_val_loss = running_loss_val\n",
    "  \n",
    "        else:\n",
    "                epochs_no_improve += 1\n",
    "        iter += 1\n",
    "                \n",
    "        if epochs_no_improve == n_epochs_stop:\n",
    "             print('Early stopping!')\n",
    "            \n",
    "\n",
    "             break\n",
    "               \n",
    "        else:\n",
    "            continue\n",
    "                \n",
    "        \n",
    "            \n",
    "        val_loss.append(epoch_val_loss)\n",
    "        train_loss.append(epoch_loss)\n",
    "    #train_accuracy.append(epoch_accuracy)\n",
    "        #print(\n",
    "            #f\"Epoch : {epoch+1} \\n\")\n",
    "        print('Split: {}'.format(i,epoch_loss,epoch_val_loss,r2_score_train, r2_score_val))                \n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - train_loss : {epoch_loss:.4f} - val_loss : {epoch_val_loss:.4f}- r2_score_train : {r2_score_train:.4f}- r2_score_val : {r2_score_val:.4f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17805d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runmymodel2(job):\n",
    "    #CREATE OUTPUT DIR\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    r2_score_train=[]\n",
    "    r2_score_val= []\n",
    "\n",
    "    labeltouse = 'CIN'\n",
    "    #input_path = '/data/processed_inputs/'\n",
    "    #input_path2 = '/data/cluster_data_v3/'\n",
    "    HPs = pd.read_csv('/mnt/scratchc/fmlab/eudari01/BREAST_METABRIC/80_SAGE_CIN_HP.txt ')\n",
    "    myhp = HPs.iloc[int(job)-1]\n",
    "    lr = myhp.lr\n",
    "    momentum=myhp.momentum\n",
    "    dropout = myhp.dropout\n",
    "    batch_size = myhp.batch_size \n",
    "    \n",
    "    \n",
    "    output_path = '/mnt/scratchc/fmlab/eudari01/BREAST_METABRIC/CIN_results'+labeltouse  + '_lr_'+str(lr)+ '_momentum_'+str(momentum)+'_dropout_'+str(dropout)+'_batch_size_'+str(batch_size)+'/'\n",
    "    try:\n",
    "        os.mkdir(output_path)\n",
    "    except:\n",
    "        print('Directory already exists!')\n",
    "\n",
    "    print('creating dirs ...')\n",
    "    print('starting CV training')\n",
    "    \n",
    "    \n",
    "    epochs=30\n",
    "    for epoch in range(1,epochs+1):\n",
    "         training(epoch)\n",
    "    \n",
    "    \n",
    "    results_df1 = pd.DataFrame()\n",
    "    \n",
    "    nametosave_epoch = 'CIN_'+labeltouse  + '_lr_'+str(lr)+ '_momentum_'+str(momentum)+'_dropout_'+str(dropout)+'_batch_size_'+str(batch_size)+'/'\n",
    "    results_df1.to_csv('/mnt/scratchc/fmlab/eudari01/BREAST_METABRIC/CIN_results' + nametosave_epoch)\n",
    "    \n",
    "    results_df2 = pd.DataFrame()\n",
    "    \n",
    "    nametosave = 'CIN_'+labeltouse  + '_lr_'+str(lr)+ '_momentum_'+str(momentum)+'_dropout_'+str(dropout)+'_batch_size_'+str(batch_size)+'/'\n",
    "    results_df1.to_csv('/mnt/scratchc/fmlab/eudari01/BREAST_METABRIC/CIN_results' + nametosave)\n",
    "    \n",
    "    print('Results saved!!')\n",
    " \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2b81c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10004/960274805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10004/960274805.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(job)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrunmymodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10004/1568992438.py\u001b[0m in \u001b[0;36mrunmymodel2\u001b[0;34m(job)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/data/processed_inputs/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minput_path2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/data/cluster_data_v3/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mHPs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/scripts/40_SAGE_CIN_HP.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmyhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHPs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def main(job):\n",
    "    runmymodel2(job)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    main(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481abcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
